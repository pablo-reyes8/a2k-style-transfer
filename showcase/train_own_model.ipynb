{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358dbfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, io, random\n",
    "from src.data.load_data import *\n",
    "from src.data.data_utils import *\n",
    "\n",
    "\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "torch.set_num_threads(1)\n",
    "torch.backends.cudnn.benchmark = True \n",
    "\n",
    "# Coniguración\n",
    "BATCH_SIZE   = 32\n",
    "PIN_MEMORY   = True\n",
    "DROP_LAST    = True\n",
    "SEED         = 7\n",
    "\n",
    "# Tamaño de entrenamiento\n",
    "SIZE         = 256\n",
    "FINAL_SIZE   = 252  # usamos RandomResizedCrop directo a 252\n",
    "\n",
    "# Targets de reducción (ajusta a gusto)\n",
    "CONTENT_KEEP = 10000   # COCO\n",
    "STYLE_KEEP   = 30000   # WikiArt\n",
    "\n",
    "# Normalización ImageNet\n",
    "IMAGENET_MEAN = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD  = [0.229, 0.224, 0.225]\n",
    "\n",
    "# Auto-select de workers (Kaggle suele tener 2 vCPU)\n",
    "CPU_COUNT = os.cpu_count() or 2\n",
    "NUM_WORKERS = 2 if CPU_COUNT <= 2 else min(4, CPU_COUNT - 1)\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "\n",
    "# ======================================================\n",
    "# Carga de COCO (content)\n",
    "# ======================================================\n",
    "coco_hf = load_dataset(\"phiyodr/coco2017\", split=\"train\")\n",
    "coco_img_col = detect_image_col(coco_hf)\n",
    "coco_hf = filter_valid_images(coco_hf, coco_img_col)\n",
    "coco_hf = cast_to_image(coco_hf, coco_img_col)\n",
    "coco_ds = HFDataset(coco_hf, img_key=\"image\", transform=content_tf)\n",
    "content_loader = make_loader(coco_ds, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "\n",
    "# Recortamos COCO a CONTENT_KEEP\n",
    "content_loader = truncate_dataloaders(content_loader, None, n=CONTENT_KEEP, seed=77)\n",
    "\n",
    "# ======================================================\n",
    "# Carga de WikiArt (style) con filtro por estilos útiles\n",
    "# ======================================================\n",
    "wiki_hf = load_dataset(\"davanstrien/wikiart-resized\", split=\"train\")\n",
    "wiki_img_col = detect_image_col(wiki_hf)\n",
    "wiki_hf = filter_valid_images(wiki_hf, wiki_img_col)\n",
    "\n",
    "print(\"Total WikiArt original:\", len(wiki_hf))\n",
    "print(\"Columnas WikiArt:\", wiki_hf.column_names)\n",
    "\n",
    "\n",
    "style_feat = wiki_hf.features[\"style\"] \n",
    "style_names = style_feat.names      \n",
    "\n",
    "print(\"Estilos disponibles:\", style_names)\n",
    "\n",
    "\n",
    "GOOD_PATTERNS = [\n",
    "    \"impression\",      \n",
    "    \"expression\",      \n",
    "    \"fauvism\",\n",
    "    \"baroque\",\n",
    "    \"romantic\",        \n",
    "    \"symbol\",         \n",
    "    \"realism\",\n",
    "    \"northern_renaissance\",\n",
    "    \"naive_art\",        \n",
    "    \"art_nouveau\",]\n",
    "\n",
    "# IDs de estilos buenos según el nombre\n",
    "good_style_ids = []\n",
    "for idx, name in enumerate(style_names):\n",
    "    name_low = name.lower()\n",
    "    if any(pat in name_low for pat in GOOD_PATTERNS):\n",
    "        good_style_ids.append(idx)\n",
    "\n",
    "print(\"IDs de estilos seleccionados:\", good_style_ids)\n",
    "print(\"Nombres de estilos seleccionados:\",\n",
    "      [style_names[i] for i in good_style_ids])\n",
    "\n",
    "def keep_good_styles(example):\n",
    "    sid = int(example[\"style\"])\n",
    "    return sid in good_style_ids\n",
    "\n",
    "\n",
    "wiki_good = wiki_hf.filter(keep_good_styles)\n",
    "print(\"Total WikiArt tras filtro por estilos buenos:\", len(wiki_good))\n",
    "STYLE_KEEP = 5000\n",
    "\n",
    "if len(wiki_good) > STYLE_KEEP:\n",
    "    try:\n",
    "        idx_good = stratified_pick(\n",
    "            wiki_good,\n",
    "            group_col=\"artist\",\n",
    "            target_total=STYLE_KEEP,\n",
    "            seed=77)\n",
    "        \n",
    "    except ValueError:\n",
    "        idx_good = stratified_pick(\n",
    "            wiki_good,\n",
    "            group_col=\"style\",\n",
    "            target_total=STYLE_KEEP,\n",
    "            seed=77)\n",
    "        \n",
    "    wiki_good = wiki_good.select(idx_good)\n",
    "\n",
    "print(\"Total final de estilos usados para NST:\", len(wiki_good))\n",
    "\n",
    "# Cast a image + dataset PyTorch\n",
    "wiki_good = wiki_good.map(add_brightness_stats, num_proc=1)\n",
    "wiki_good = wiki_good.filter(keep_reasonable_brightness, num_proc=1)\n",
    "print(\"Total WikiArt tras filtro style + brillo/contraste:\", len(wiki_good))\n",
    "wiki_good = cast_to_image(wiki_good, wiki_img_col)\n",
    "wiki_ds = HFDataset(wiki_good, img_key=\"image\", transform=style_tf)\n",
    "style_loader = make_loader(wiki_ds, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)\n",
    "\n",
    "\n",
    "\n",
    "train_iter = make_train_iterator(content_loader, style_loader)\n",
    "xb_c, xb_s = next(iter(train_iter))\n",
    "print(\"paired content:\", xb_c.shape, \"| paired style:\", xb_s.shape)\n",
    "print(\"len(content_loader) =\", len(content_loader))\n",
    "print(\"len(style_loader) =\", len(style_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7a196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model.styA2kNet import * \n",
    "from src.model.loss import * \n",
    "from src.training.train_model import *\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = StyA2KNet(device=device).to(device)\n",
    "vgg_loss_extractor = build_vgg_loss_extractor(device)\n",
    "criterion = PerceptualLoss(vgg_loss_extractor).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Usando {torch.cuda.device_count()} GPUs con DataParallel\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    \n",
    "state = train_stya2k(\n",
    "    model=model,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    content_loader=content_loader,\n",
    "    style_loader=style_loader,\n",
    "    device=device,\n",
    "    epochs=20,\n",
    "    amp_enabled=True,\n",
    "    amp_dtype=\"bp16\",\n",
    "    grad_clip=1.0,\n",
    "    log_every=100,\n",
    "    run_name=\"StyA2K_v1\",\n",
    "    sample_every=2,\n",
    "    sample_dir=\"samples_stya2k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a451b1",
   "metadata": {},
   "source": [
    "## Usando 2 GPUs con DataParallel\n",
    "\n",
    "Run: StyA2K_v1\n",
    "Device: cuda | AMP: True (bp16) | epochs: 20 | start_epoch=0\n",
    "\n",
    "---\n",
    "\n",
    "## ep | step | loss | content | style | imgs | imgs/s | time\n",
    "\n",
    "[step 100/312] loss=29.8137 content=16.4376 style=13.3761 time=608.7s\n",
    "\n",
    "[step 200/312] loss=27.9632 content=14.7957 style=13.1675 time=1184.1s\n",
    "\n",
    "[step 300/312] loss=26.4480 content=13.8558 style=12.5922 time=1759.3s\n",
    "\n",
    "0 | 312 | 26.32192 | 13.77635 | 12.54558 | 9984 | 5.5 | 30:28\n",
    "\n",
    "└─ [SAMPLE] grid guardada en samples_stya2k/StyA2K_v1_e000.png\n",
    "\n",
    "[step 100/312] loss=25.0838 content=11.5879 style=13.4959 time=600.3s\n",
    "\n",
    "[step 200/312] loss=23.1558 content=11.3300 style=11.8258 time=1176.1s\n",
    "\n",
    "[step 300/312] loss=22.4681 content=11.1548 style=11.3133 time=1751.4s\n",
    "\n",
    "1 | 624 | 22.61840 | 11.14136 | 11.47704 | 9984 | 5.5 | 30:20\n",
    "\n",
    "[step 100/312] loss=20.9399 content=10.5985 style=10.3414 time=581.0s\n",
    "\n",
    "[step 200/312] loss=21.0096 content=10.4871 style=10.5225 time=1156.6s\n",
    "\n",
    "[step 300/312] loss=20.6936 content=10.3809 style=10.3127 time=1732.5s\n",
    "\n",
    "2 | 936 | 20.67360 | 10.36999 | 10.30361 | 9984 | 5.5 | 30:01\n",
    "\n",
    "└─ [SAMPLE] grid guardada en samples_stya2k/StyA2K_v1_e002.png\n",
    "\n",
    "[step 100/312] loss=21.4734 content=10.1112 style=11.3622 time=598.1s\n",
    "\n",
    "[step 200/312] loss=20.4882 content=9.9646 style=10.5236 time=1172.0s\n",
    "\n",
    "[step 300/312] loss=20.2428 content=9.9101 style=10.3327 time=1746.8s\n",
    "\n",
    "3 | 1248 | 20.21931 | 9.90737 | 10.31194 | 9984 | 5.5 | 30:15\n",
    "\n",
    "[step 100/312] loss=19.9675 content=9.6761 style=10.2914 time=579.8s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4cdfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = train_stya2k(\n",
    "    model=model,                 \n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,          \n",
    "    content_loader=content_loader,\n",
    "    style_loader=style_loader,\n",
    "    device=device,\n",
    "    epochs=10,                  \n",
    "    amp_enabled=True,\n",
    "    amp_dtype=\"fp16\",\n",
    "    grad_clip=1.0,\n",
    "    log_every=100,\n",
    "    run_name=\"StyA2K_v1\",\n",
    "    sample_every=2,\n",
    "    sample_dir=\"samples_stya2k\",\n",
    "    # --- claves de reanudación ---\n",
    "    start_epoch=state[\"last_epoch\"] + 1,\n",
    "    init_global_step=state[\"global_step\"],\n",
    "    scaler_state_dict=state[\"scaler_state_dict\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
